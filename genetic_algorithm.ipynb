{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zuOtc0bo6tGB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Sriharsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2nYD1Drm799g"
      },
      "outputs": [],
      "source": [
        "SEED = 2018\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xPPgXqcx8BoT"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = pd.read_csv('content/dataset/android_dataset-v2.csv')\n",
        "Y = dataset['class']\n",
        "X = dataset.drop(['class'], axis=1)\n",
        "features = X.columns\n",
        "X.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Fa6zopir9jO-"
      },
      "outputs": [],
      "source": [
        "encoder = LabelEncoder().fit(Y)\n",
        "Y = encoder.transform(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "dAtr4Qh-Lt77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "utYsljSR9F2E",
        "outputId": "4e7e3167-6ff7-4066-f6e8-5a6163a9a20b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV MSE before feature selection: 0.11\n"
          ]
        }
      ],
      "source": [
        "est = SVC()\n",
        "score = -1.0 * cross_val_score(est, X, Y, cv=5, scoring=\"neg_mean_squared_error\")\n",
        "print(\"CV MSE before feature selection: {:.2f}\".format(np.mean(score)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "q4AMXBbq92Xf"
      },
      "outputs": [],
      "source": [
        "class GeneticSelector():\n",
        "    def __init__(self, estimator, n_gen, size, n_best, n_rand, \n",
        "                 n_children, mutation_rate):\n",
        "        # Estimator \n",
        "        self.estimator = estimator\n",
        "        # Number of generations\n",
        "        self.n_gen = n_gen\n",
        "        # Number of chromosomes in population\n",
        "        self.size = size\n",
        "        # Number of best chromosomes to select\n",
        "        self.n_best = n_best\n",
        "        # Number of random chromosomes to select\n",
        "        self.n_rand = n_rand\n",
        "        # Number of children created during crossover\n",
        "        self.n_children = n_children\n",
        "        # Probablity of chromosome mutation\n",
        "        self.mutation_rate = mutation_rate\n",
        "        \n",
        "        if int((self.n_best + self.n_rand) / 2) * self.n_children != self.size:\n",
        "            raise ValueError(\"The population size is not stable.\")  \n",
        "            \n",
        "    def initilize(self):\n",
        "        population = []\n",
        "        for i in range(self.size):\n",
        "            chromosome = np.ones(self.n_features, dtype=bool)\n",
        "            mask = np.random.rand(len(chromosome)) < 0.3\n",
        "            chromosome[mask] = False\n",
        "            population.append(chromosome)\n",
        "        return population\n",
        "\n",
        "    def fitness(self, population):\n",
        "        X, y = self.dataset\n",
        "        scores = []\n",
        "        for chromosome in population:\n",
        "            score = -1.0 * np.mean(cross_val_score(self.estimator, X[:,chromosome], y, \n",
        "                                                       cv=5, \n",
        "                                                       scoring=\"neg_mean_squared_error\"))\n",
        "            scores.append(score)\n",
        "        scores, population = np.array(scores), np.array(population) \n",
        "        inds = np.argsort(scores)\n",
        "        return list(scores[inds]), list(population[inds,:])\n",
        "\n",
        "    def select(self, population_sorted):\n",
        "        population_next = []\n",
        "        for i in range(self.n_best):\n",
        "            population_next.append(population_sorted[i])\n",
        "        for i in range(self.n_rand):\n",
        "            population_next.append(random.choice(population_sorted))\n",
        "        random.shuffle(population_next)\n",
        "        return population_next\n",
        "\n",
        "    def crossover(self, population):\n",
        "        population_next = []\n",
        "        for i in range(int(len(population)/2)):\n",
        "            for j in range(self.n_children):\n",
        "                chromosome1, chromosome2 = population[i], population[len(population)-1-i]\n",
        "                child = chromosome1\n",
        "                mask = np.random.rand(len(child)) > 0.5\n",
        "                child[mask] = chromosome2[mask]\n",
        "                population_next.append(child)\n",
        "        return population_next\n",
        "\t\n",
        "    def mutate(self, population):\n",
        "        population_next = []\n",
        "        for i in range(len(population)):\n",
        "            chromosome = population[i]\n",
        "            if random.random() < self.mutation_rate:\n",
        "                mask = np.random.rand(len(chromosome)) < 0.05\n",
        "                chromosome[mask] = False\n",
        "            population_next.append(chromosome)\n",
        "        return population_next\n",
        "\n",
        "    def generate(self, population):\n",
        "        # Selection, crossover and mutation\n",
        "        scores_sorted, population_sorted = self.fitness(population)\n",
        "        population = self.select(population_sorted)\n",
        "        population = self.crossover(population)\n",
        "        population = self.mutate(population)\n",
        "        # History\n",
        "        self.chromosomes_best.append(population_sorted[0])\n",
        "        self.scores_best.append(scores_sorted[0])\n",
        "        self.scores_avg.append(np.mean(scores_sorted))\n",
        "        \n",
        "        return population\n",
        "\n",
        "    def fit(self, X, y):\n",
        " \n",
        "        self.chromosomes_best = []\n",
        "        self.scores_best, self.scores_avg  = [], []\n",
        "        \n",
        "        self.dataset = X, y\n",
        "        self.n_features = X.shape[1]\n",
        "        g = 1\n",
        "        population = self.initilize()\n",
        "        for i in range(self.n_gen):\n",
        "            population = self.generate(population)\n",
        "            print('generation:', g)\n",
        "            g+=1\n",
        "        return self \n",
        "    \n",
        "    @property\n",
        "    def support_(self):\n",
        "        return self.chromosomes_best[-1]\n",
        "\n",
        "    def plot_scores(self):\n",
        "        plt.plot(self.scores_best, label='Best')\n",
        "        plt.plot(self.scores_avg, label='Average')\n",
        "        plt.legend()\n",
        "        plt.ylabel('Scores')\n",
        "        plt.xlabel('Generation')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "colab_type": "code",
        "id": "ap661Hrw9_kP",
        "outputId": "26226415-dcd5-4fde-d02a-59b4b4c45aa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generation: 1\n",
            "generation: 2\n",
            "generation: 3\n",
            "generation: 4\n",
            "generation: 5\n",
            "generation: 6\n",
            "generation: 7\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "X = X.values\n",
        "sel = GeneticSelector(estimator=SVC(), \n",
        "                      n_gen=7, size=200, n_best=40, n_rand=40, \n",
        "                      n_children=5, mutation_rate=0.05)\n",
        "sel.fit(X, Y)\n",
        "sel.plot_scores()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "YshFnIbwWV9x",
        "outputId": "fbc72569-0176-4193-cca3-9c00961099be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV MSE after feature selection: 0.11\n"
          ]
        }
      ],
      "source": [
        "\n",
        "score = -1.0 * cross_val_score(est, X[:,sel.support_], Y, cv=5, scoring=\"neg_mean_squared_error\")\n",
        "print(\"CV MSE after feature selection: {:.2f}\".format(np.mean(score)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7yfUwBRlWpx7"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle.dump(sel, open('../ga.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "VaHfWUC81vdW"
      },
      "outputs": [],
      "source": [
        "# sel = pickle.load(open('/content/drive/My Drive/Android-Malware-Detection/ga.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BZQ6Y2QTaisY"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "APdtIsXuYuZW",
        "outputId": "d9b0e427-23b3-434f-ef28-1c30baeb46bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Sriharsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\Sriharsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Epoch 1/175\n",
            "WARNING:tensorflow:From c:\\Users\\Sriharsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\Sriharsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "42/42 [==============================] - 3s 6ms/step - loss: 0.6688 - accuracy: 0.6783\n",
            "Epoch 2/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.6520 - accuracy: 0.6813\n",
            "Epoch 3/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.6348 - accuracy: 0.6791\n",
            "Epoch 4/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.6248 - accuracy: 0.6806\n",
            "Epoch 5/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.6111 - accuracy: 0.6813\n",
            "Epoch 6/175\n",
            "42/42 [==============================] - 2s 43ms/step - loss: 0.5940 - accuracy: 0.6821\n",
            "Epoch 7/175\n",
            "42/42 [==============================] - 0s 11ms/step - loss: 0.5876 - accuracy: 0.6850\n",
            "Epoch 8/175\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.5718 - accuracy: 0.6932\n",
            "Epoch 9/175\n",
            "42/42 [==============================] - 0s 10ms/step - loss: 0.5584 - accuracy: 0.7066\n",
            "Epoch 10/175\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.5427 - accuracy: 0.7275\n",
            "Epoch 11/175\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.5225 - accuracy: 0.7506\n",
            "Epoch 12/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.5030 - accuracy: 0.7640\n",
            "Epoch 13/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.4817 - accuracy: 0.7885\n",
            "Epoch 14/175\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.4707 - accuracy: 0.7863\n",
            "Epoch 15/175\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.4614 - accuracy: 0.7975\n",
            "Epoch 16/175\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.4483 - accuracy: 0.8042\n",
            "Epoch 17/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.8243\n",
            "Epoch 18/175\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.8392\n",
            "Epoch 19/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.8302\n",
            "Epoch 20/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8161\n",
            "Epoch 21/175\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8325\n",
            "Epoch 22/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8354\n",
            "Epoch 23/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8354\n",
            "Epoch 24/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8459\n",
            "Epoch 25/175\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.3821 - accuracy: 0.8474\n",
            "Epoch 26/175\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.3853 - accuracy: 0.8444\n",
            "Epoch 27/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3772 - accuracy: 0.8518\n",
            "Epoch 28/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3734 - accuracy: 0.8541\n",
            "Epoch 29/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3718 - accuracy: 0.8496\n",
            "Epoch 30/175\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.3674 - accuracy: 0.8585\n",
            "Epoch 31/175\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.3650 - accuracy: 0.8608\n",
            "Epoch 32/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3645 - accuracy: 0.8563\n",
            "Epoch 33/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3583 - accuracy: 0.8593\n",
            "Epoch 34/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3602 - accuracy: 0.8578\n",
            "Epoch 35/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3529 - accuracy: 0.8555\n",
            "Epoch 36/175\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.3542 - accuracy: 0.8675\n",
            "Epoch 37/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3412 - accuracy: 0.8622\n",
            "Epoch 38/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3510 - accuracy: 0.8652\n",
            "Epoch 39/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3365 - accuracy: 0.8682\n",
            "Epoch 40/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3389 - accuracy: 0.8682\n",
            "Epoch 41/175\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.3333 - accuracy: 0.8682\n",
            "Epoch 42/175\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.3331 - accuracy: 0.8675\n",
            "Epoch 43/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3259 - accuracy: 0.8779\n",
            "Epoch 44/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3240 - accuracy: 0.8786\n",
            "Epoch 45/175\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.3189 - accuracy: 0.8809\n",
            "Epoch 46/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3230 - accuracy: 0.8786\n",
            "Epoch 47/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3259 - accuracy: 0.8757\n",
            "Epoch 48/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3106 - accuracy: 0.8846\n",
            "Epoch 49/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3227 - accuracy: 0.8697\n",
            "Epoch 50/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.3094 - accuracy: 0.8816\n",
            "Epoch 51/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3132 - accuracy: 0.8891\n",
            "Epoch 52/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3208 - accuracy: 0.8831\n",
            "Epoch 53/175\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.3123 - accuracy: 0.8928\n",
            "Epoch 54/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.3038 - accuracy: 0.8876\n",
            "Epoch 55/175\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.3017 - accuracy: 0.8905\n",
            "Epoch 56/175\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.3051 - accuracy: 0.8905\n",
            "Epoch 57/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.2964 - accuracy: 0.8898\n",
            "Epoch 58/175\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.2976 - accuracy: 0.8928\n",
            "Epoch 59/175\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.2858 - accuracy: 0.9032\n",
            "Epoch 60/175\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.2854 - accuracy: 0.8965\n",
            "Epoch 61/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2858 - accuracy: 0.8943\n",
            "Epoch 62/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2862 - accuracy: 0.8928\n",
            "Epoch 63/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2961 - accuracy: 0.8987\n",
            "Epoch 64/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2825 - accuracy: 0.8987\n",
            "Epoch 65/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2784 - accuracy: 0.8980\n",
            "Epoch 66/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2765 - accuracy: 0.9047\n",
            "Epoch 67/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2839 - accuracy: 0.9017\n",
            "Epoch 68/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2781 - accuracy: 0.9002\n",
            "Epoch 69/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2797 - accuracy: 0.9025\n",
            "Epoch 70/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2803 - accuracy: 0.9017\n",
            "Epoch 71/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2803 - accuracy: 0.9017\n",
            "Epoch 72/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2649 - accuracy: 0.9092\n",
            "Epoch 73/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2594 - accuracy: 0.9129\n",
            "Epoch 74/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2606 - accuracy: 0.9077\n",
            "Epoch 75/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.2564 - accuracy: 0.9106\n",
            "Epoch 76/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2571 - accuracy: 0.9069\n",
            "Epoch 77/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2591 - accuracy: 0.9106\n",
            "Epoch 78/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2638 - accuracy: 0.9032\n",
            "Epoch 79/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2522 - accuracy: 0.9144\n",
            "Epoch 80/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2485 - accuracy: 0.9159\n",
            "Epoch 81/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2549 - accuracy: 0.9092\n",
            "Epoch 82/175\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.2596 - accuracy: 0.9017\n",
            "Epoch 83/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2419 - accuracy: 0.9188\n",
            "Epoch 84/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2515 - accuracy: 0.9136\n",
            "Epoch 85/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2401 - accuracy: 0.9144\n",
            "Epoch 86/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.2450 - accuracy: 0.9151\n",
            "Epoch 87/175\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.2282 - accuracy: 0.9241\n",
            "Epoch 88/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.2329 - accuracy: 0.9226\n",
            "Epoch 89/175\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.2418 - accuracy: 0.9151\n",
            "Epoch 90/175\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.2337 - accuracy: 0.9196\n",
            "Epoch 91/175\n",
            "42/42 [==============================] - 1s 12ms/step - loss: 0.2269 - accuracy: 0.9248\n",
            "Epoch 92/175\n",
            "42/42 [==============================] - 0s 10ms/step - loss: 0.2354 - accuracy: 0.9203\n",
            "Epoch 93/175\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.2197 - accuracy: 0.9285\n",
            "Epoch 94/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.2254 - accuracy: 0.9181\n",
            "Epoch 95/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.2317 - accuracy: 0.9226\n",
            "Epoch 96/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.2232 - accuracy: 0.9293\n",
            "Epoch 97/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.2270 - accuracy: 0.9233\n",
            "Epoch 98/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.2257 - accuracy: 0.9255\n",
            "Epoch 99/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.2185 - accuracy: 0.9315\n",
            "Epoch 100/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.2206 - accuracy: 0.9278\n",
            "Epoch 101/175\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.2232 - accuracy: 0.9241\n",
            "Epoch 102/175\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.2154 - accuracy: 0.9270\n",
            "Epoch 103/175\n",
            "42/42 [==============================] - 0s 10ms/step - loss: 0.2144 - accuracy: 0.9270\n",
            "Epoch 104/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.2189 - accuracy: 0.9278\n",
            "Epoch 105/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.2142 - accuracy: 0.9263\n",
            "Epoch 106/175\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.2142 - accuracy: 0.9263\n",
            "Epoch 107/175\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.2196 - accuracy: 0.9248\n",
            "Epoch 108/175\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.2016 - accuracy: 0.9337\n",
            "Epoch 109/175\n",
            "42/42 [==============================] - 0s 11ms/step - loss: 0.1989 - accuracy: 0.9367\n",
            "Epoch 110/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.2043 - accuracy: 0.9352\n",
            "Epoch 111/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1874 - accuracy: 0.9389\n",
            "Epoch 112/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.2053 - accuracy: 0.9308\n",
            "Epoch 113/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2054 - accuracy: 0.9330\n",
            "Epoch 114/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2051 - accuracy: 0.9255\n",
            "Epoch 115/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.2014 - accuracy: 0.9293\n",
            "Epoch 116/175\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.1974 - accuracy: 0.9293\n",
            "Epoch 117/175\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.1958 - accuracy: 0.9293\n",
            "Epoch 118/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1915 - accuracy: 0.9389\n",
            "Epoch 119/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1960 - accuracy: 0.9345\n",
            "Epoch 120/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1937 - accuracy: 0.9375\n",
            "Epoch 121/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1905 - accuracy: 0.9397\n",
            "Epoch 122/175\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.1923 - accuracy: 0.9375\n",
            "Epoch 123/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1808 - accuracy: 0.9419\n",
            "Epoch 124/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1898 - accuracy: 0.9367\n",
            "Epoch 125/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.1774 - accuracy: 0.9434\n",
            "Epoch 126/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1894 - accuracy: 0.9345\n",
            "Epoch 127/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1735 - accuracy: 0.9427\n",
            "Epoch 128/175\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.1758 - accuracy: 0.9360\n",
            "Epoch 129/175\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.1820 - accuracy: 0.9404\n",
            "Epoch 130/175\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.1832 - accuracy: 0.9367\n",
            "Epoch 131/175\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.1807 - accuracy: 0.9412\n",
            "Epoch 132/175\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.1658 - accuracy: 0.9471\n",
            "Epoch 133/175\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.1797 - accuracy: 0.9352\n",
            "Epoch 134/175\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.1721 - accuracy: 0.9427\n",
            "Epoch 135/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1697 - accuracy: 0.9464\n",
            "Epoch 136/175\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.1603 - accuracy: 0.9449\n",
            "Epoch 137/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1704 - accuracy: 0.9434\n",
            "Epoch 138/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.1669 - accuracy: 0.9434\n",
            "Epoch 139/175\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.1560 - accuracy: 0.9479\n",
            "Epoch 140/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1634 - accuracy: 0.9442\n",
            "Epoch 141/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1506 - accuracy: 0.9516\n",
            "Epoch 142/175\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.1629 - accuracy: 0.9464\n",
            "Epoch 143/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1736 - accuracy: 0.9456\n",
            "Epoch 144/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1594 - accuracy: 0.9464\n",
            "Epoch 145/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1602 - accuracy: 0.9471\n",
            "Epoch 146/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.1608 - accuracy: 0.9449\n",
            "Epoch 147/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1597 - accuracy: 0.9434\n",
            "Epoch 148/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1565 - accuracy: 0.9442\n",
            "Epoch 149/175\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.1557 - accuracy: 0.9442\n",
            "Epoch 150/175\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.1583 - accuracy: 0.9442\n",
            "Epoch 151/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1511 - accuracy: 0.9509\n",
            "Epoch 152/175\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.1546 - accuracy: 0.9509\n",
            "Epoch 153/175\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.1525 - accuracy: 0.9509\n",
            "Epoch 154/175\n",
            "42/42 [==============================] - 1s 12ms/step - loss: 0.1530 - accuracy: 0.9486\n",
            "Epoch 155/175\n",
            "42/42 [==============================] - 0s 11ms/step - loss: 0.1493 - accuracy: 0.9501\n",
            "Epoch 156/175\n",
            "42/42 [==============================] - 0s 9ms/step - loss: 0.1485 - accuracy: 0.9538\n",
            "Epoch 157/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1609 - accuracy: 0.9464\n",
            "Epoch 158/175\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.1491 - accuracy: 0.9509\n",
            "Epoch 159/175\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.1458 - accuracy: 0.9479\n",
            "Epoch 160/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1595 - accuracy: 0.9449\n",
            "Epoch 161/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1395 - accuracy: 0.9516\n",
            "Epoch 162/175\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.1412 - accuracy: 0.9486\n",
            "Epoch 163/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1341 - accuracy: 0.9598\n",
            "Epoch 164/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1394 - accuracy: 0.9516\n",
            "Epoch 165/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1424 - accuracy: 0.9464\n",
            "Epoch 166/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1323 - accuracy: 0.9546\n",
            "Epoch 167/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1414 - accuracy: 0.9509\n",
            "Epoch 168/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1398 - accuracy: 0.9523\n",
            "Epoch 169/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1469 - accuracy: 0.9434\n",
            "Epoch 170/175\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.1367 - accuracy: 0.9523\n",
            "Epoch 171/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.1436 - accuracy: 0.9538\n",
            "Epoch 172/175\n",
            "42/42 [==============================] - 0s 5ms/step - loss: 0.1343 - accuracy: 0.9531\n",
            "Epoch 173/175\n",
            "42/42 [==============================] - 0s 4ms/step - loss: 0.1379 - accuracy: 0.9561\n",
            "Epoch 174/175\n",
            "42/42 [==============================] - 0s 6ms/step - loss: 0.1290 - accuracy: 0.9538\n",
            "Epoch 175/175\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.1492 - accuracy: 0.9479\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.2383 - accuracy: 0.9137\n",
            "\n",
            "loss: 23.83%\n",
            "\n",
            "accuracy: 91.37%\n"
          ]
        }
      ],
      "source": [
        "AN = Sequential()\n",
        "AN.add(Dense(256, input_dim = 302, activation='relu'))\n",
        "AN.add(Dropout(0.2))\n",
        "AN.add(Dense(128, activation='relu'))\n",
        "AN.add(Dropout(0.2))\n",
        "AN.add(Dense(128, activation='relu'))\n",
        "AN.add(Dropout(0.3))\n",
        "AN.add(Dense(32, activation='relu'))\n",
        "AN.add(Dropout(0.2))\n",
        "AN.add(Dense(1, activation='sigmoid'))\n",
        "AN.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "AN.fit(X_train[:,sel.support_], y_train, epochs=175, batch_size=32)\n",
        "\n",
        "scores = AN.evaluate(X_test[:,sel.support_], y_test)\n",
        "for i in range(len(scores)):\n",
        "  print(\"\\n%s: %.2f%%\" % (AN.metrics_names[i], scores[i]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "oMzDdcDd_Hla"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: androguard in c:\\users\\sriharsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.3.5)\n",
            "Requirement already satisfied: asn1crypto>=0.24.0 in c:\\users\\sriharsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from androguard) (1.5.1)\n",
            "Requirement already satisfied: click in c:\\users\\sriharsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from androguard) (8.1.6)\n",
            "Requirement already satisfied: colorama in c:\\users\\sriharsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from androguard) (0.4.6)\n",
            "Requirement already satisfied: future in c:\\users\\sriharsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from androguard) (0.18.3)\n",
            "Requirement already satisfied: ipython>=5.0.0 in c:\\users\\sriharsh\\appdata\\roaming\\python\\python311\\site-packages (from androguard) (8.14.0)\n",
            "Requirement already satisfied: lxml in c:\\users\\sriharsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from androguard) (4.9.3)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\sriharsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from androguard) (3.7.2)\n",
            "Requirement already satisfied: networkx>=1.11 in c:\\users\\sriharsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from androguard) (3.1)\n",
            "Requirement already satisfied: pydot>=1.4.1 in c:\\users\\sriharsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from androguard) (1.4.2)\n",
            "Requirement already satisfied: pygments in c:\\users\\sriharsh\\appdata\\roaming\\python\\python311\\site-packages (from androguard) (2.16.1)\n",
            "Requirement already satisfied: backcall in c:\\users\\sriharsh\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=5.0.0->androguard) (0.2.0)\n",
            "Requirement already satisfied: decorator in c:\\users\\sriharsh\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=5.0.0->androguard) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\sriharsh\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=5.0.0->androguard) (0.19.0)\n",
            "Requirement already satisfied: matplotlib-inline in c:\\users\\sriharsh\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=5.0.0->androguard) (0.1.6)\n",
            "Requirement already satisfied: pickleshare in c:\\users\\sriharsh\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=5.0.0->androguard) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\sriharsh\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=5.0.0->androguard) (3.0.39)\n",
            "Requirement already satisfied: stack-data in c:\\users\\sriharsh\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=5.0.0->androguard) (0.6.2)\n",
            "Requirement already satisfied: traitlets>=5 in c:\\users\\sriharsh\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=5.0.0->androguard) (5.9.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\sriharsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydot>=1.4.1->androguard) (3.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sriharsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->androguard) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\sriharsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->androguard) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sriharsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->androguard) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sriharsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->androguard) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in c:\\users\\sriharsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->androguard) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\sriharsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->androguard) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\sriharsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->androguard) (10.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sriharsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->androguard) (2.8.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\sriharsh\\appdata\\roaming\\python\\python311\\site-packages (from jedi>=0.16->ipython>=5.0.0->androguard) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\sriharsh\\appdata\\roaming\\python\\python311\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=5.0.0->androguard) (0.2.6)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\sriharsh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->androguard) (1.16.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in c:\\users\\sriharsh\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=5.0.0->androguard) (1.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\sriharsh\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=5.0.0->androguard) (2.2.1)\n",
            "Requirement already satisfied: pure-eval in c:\\users\\sriharsh\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=5.0.0->androguard) (0.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install androguard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "colab_type": "code",
        "id": "JCOxEMKx_EOz",
        "outputId": "cd8f1134-873f-41e5-f3a5-6acfb1a727d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['android.permission.READ_EXTERNAL_STORAGE', 'com.sonymobile.home.permission.PROVIDER_INSERT_BADGE', 'android.permission.AUTHENTICATE_ACCOUNTS', 'android.permission.READ_PROFILE', 'android.permission.READ_PHONE_STATE', 'android.permission.READ_CONTACTS', 'android.permission.ACCESS_WIFI_STATE', 'android.permission.INSTALL_SHORTCUT', 'android.permission.REQUEST_INSTALL_PACKAGES', 'android.permission.WRITE_CONTACTS', 'android.permission.MANAGE_ACCOUNTS', 'android.permission.ACCESS_NETWORK_STATE', 'com.whatsapp.permission.MAPS_RECEIVE', 'com.sec.android.provider.badge.permission.WRITE', 'com.whatsapp.permission.BROADCAST', 'android.permission.RECORD_AUDIO', 'android.permission.NFC', 'android.permission.USE_FULL_SCREEN_INTENT', 'com.whatsapp.permission.REGISTRATION', 'android.permission.WAKE_LOCK', 'com.android.launcher.permission.INSTALL_SHORTCUT', 'android.permission.FOREGROUND_SERVICE', 'android.permission.VIBRATE', 'com.google.android.providers.gsf.permission.READ_GSERVICES', 'android.permission.USE_BIOMETRIC', 'android.permission.GET_ACCOUNTS', 'android.permission.USE_CREDENTIALS', 'com.sec.android.provider.badge.permission.READ', 'com.huawei.android.launcher.permission.WRITE_SETTINGS', 'android.permission.ACCESS_FINE_LOCATION', 'android.permission.GET_TASKS', 'android.permission.READ_SYNC_SETTINGS', 'android.permission.WRITE_SYNC_SETTINGS', 'android.permission.READ_SYNC_STATS', 'com.huawei.android.launcher.permission.READ_SETTINGS', 'com.huawei.android.launcher.permission.CHANGE_BADGE', 'com.google.android.c2dm.permission.RECEIVE', 'android.permission.RECEIVE_SMS', 'android.permission.BLUETOOTH', 'android.permission.MODIFY_AUDIO_SETTINGS', 'android.permission.WRITE_EXTERNAL_STORAGE', 'com.sonyericsson.home.permission.BROADCAST_BADGE', 'android.permission.ACCESS_COARSE_LOCATION', 'com.whatsapp.sticker.READ', 'android.permission.CAMERA', 'android.permission.BROADCAST_STICKY', 'android.permission.CHANGE_NETWORK_STATE', 'android.permission.SEND_SMS', 'com.android.launcher.permission.UNINSTALL_SHORTCUT', 'com.htc.launcher.permission.UPDATE_SHORTCUT', 'android.permission.INTERNET', 'android.permission.USE_FINGERPRINT', 'android.permission.CHANGE_WIFI_STATE', 'android.permission.RECEIVE_BOOT_COMPLETED', 'android.permission.MANAGE_OWN_CALLS', 'com.htc.launcher.permission.READ_SETTINGS']\n"
          ]
        }
      ],
      "source": [
        "from androguard.core.bytecodes.apk import APK\n",
        "\n",
        "def predict(apk):\n",
        "  vector = {}\n",
        "  a = APK(apk)\n",
        "  perm = a.get_permissions()\n",
        "  print(perm)\n",
        "  for d in features:\n",
        "    if d in perm:\n",
        "      vector[d]=1\n",
        "    else:\n",
        "      vector[d]=0\n",
        "  data = [ v for v in vector.values() ]\n",
        "  data = np.array(data)\n",
        "  print(\"Shape of input data:\", data.shape)\n",
        "  print(\"Input data:\", data)\n",
        "  print(\"Model input shape:\", AN.input_shape)\n",
        "  print(AN.predict([data]))\n",
        "  # print(data[sel.support_])\n",
        "  print(AN.predict([[data[sel.support_]]]))\n",
        "\n",
        "#predict('/content/drive/My Drive/Android-Malware-Detection/dataset/malign/com.prasesfee.apk')\n",
        "predict('content\\dataset\\benign\\whatsapp.apk')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NkpoJhZU2oNU"
      },
      "outputs": [],
      "source": [
        "pickle.dump(AN, open('../ANN_GA.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "POwapCpMI9Uo"
      },
      "source": [
        "# **SVC**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XhXehxsa8UL5"
      },
      "outputs": [],
      "source": [
        "Y = dataset['class']\n",
        "X = dataset.drop(['class'], axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "eJ72_CtV6q5s",
        "outputId": "8b97335c-872e-4639-dda3-c77304faa367"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 75 candidates, totalling 375 fits\n",
            "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.677 total time=   0.3s\n",
            "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.684 total time=   0.2s\n",
            "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.684 total time=   0.3s\n",
            "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.687 total time=   0.2s\n",
            "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.679 total time=   0.2s\n",
            "[CV 1/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.703 total time=   0.1s\n",
            "[CV 2/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.695 total time=   0.1s\n",
            "[CV 3/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.684 total time=   0.1s\n",
            "[CV 4/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.683 total time=   0.1s\n",
            "[CV 5/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.672 total time=   0.1s\n",
            "[CV 1/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.877 total time=   0.0s\n",
            "[CV 2/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.885 total time=   0.0s\n",
            "[CV 3/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.836 total time=   0.0s\n",
            "[CV 5/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.869 total time=   0.0s\n",
            "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.822 total time=   0.1s\n",
            "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.859 total time=   0.1s\n",
            "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.844 total time=   0.1s\n",
            "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.813 total time=   0.1s\n",
            "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.840 total time=   0.1s\n",
            "[CV 1/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.796 total time=   0.0s\n",
            "[CV 2/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.825 total time=   0.0s\n",
            "[CV 3/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.796 total time=   0.0s\n",
            "[CV 4/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.787 total time=   0.1s\n",
            "[CV 5/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.817 total time=   0.1s\n",
            "[CV 1/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.877 total time=   0.0s\n",
            "[CV 2/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.885 total time=   0.0s\n",
            "[CV 3/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.836 total time=   0.0s\n",
            "[CV 5/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.869 total time=   0.0s\n",
            "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.729 total time=   0.1s\n",
            "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.755 total time=   0.2s\n",
            "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.725 total time=   0.1s\n",
            "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.746 total time=   0.1s\n",
            "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.761 total time=   0.1s\n",
            "[CV 1/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.677 total time=   0.1s\n",
            "[CV 2/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.677 total time=   0.1s\n",
            "[CV 3/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.680 total time=   0.1s\n",
            "[CV 4/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.679 total time=   0.0s\n",
            "[CV 5/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.679 total time=   0.1s\n",
            "[CV 1/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.877 total time=   0.0s\n",
            "[CV 2/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.885 total time=   0.0s\n",
            "[CV 3/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.836 total time=   0.0s\n",
            "[CV 5/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.869 total time=   0.0s\n",
            "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.677 total time=   0.2s\n",
            "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.677 total time=   0.1s\n",
            "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.680 total time=   0.1s\n",
            "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.679 total time=   0.1s\n",
            "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.679 total time=   0.1s\n",
            "[CV 1/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.677 total time=   0.1s\n",
            "[CV 2/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.677 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.680 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.679 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.679 total time=   0.0s\n",
            "[CV 1/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.877 total time=   0.0s\n",
            "[CV 2/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.885 total time=   0.0s\n",
            "[CV 3/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.836 total time=   0.0s\n",
            "[CV 5/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.869 total time=   0.0s\n",
            "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.677 total time=   0.0s\n",
            "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.677 total time=   0.1s\n",
            "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.680 total time=   0.1s\n",
            "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.679 total time=   0.1s\n",
            "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.679 total time=   0.1s\n",
            "[CV 1/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.677 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.677 total time=   0.1s\n",
            "[CV 3/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.680 total time=   0.1s\n",
            "[CV 4/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.679 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.679 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.877 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.885 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.836 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.869 total time=   0.0s\n",
            "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.862 total time=   0.1s\n",
            "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.907 total time=   0.1s\n",
            "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.859 total time=   0.1s\n",
            "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.806 total time=   0.1s\n",
            "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.869 total time=   0.1s\n",
            "[CV 1/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.628 total time=   0.0s\n",
            "[CV 2/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.587 total time=   0.1s\n",
            "[CV 3/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.576 total time=   0.0s\n",
            "[CV 4/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.563 total time=   0.0s\n",
            "[CV 5/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.586 total time=   0.1s\n",
            "[CV 1/5] END .......C=1, gamma=1, kernel=linear;, score=0.870 total time=   0.0s\n",
            "[CV 2/5] END .......C=1, gamma=1, kernel=linear;, score=0.881 total time=   0.0s\n",
            "[CV 3/5] END .......C=1, gamma=1, kernel=linear;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END .......C=1, gamma=1, kernel=linear;, score=0.851 total time=   0.0s\n",
            "[CV 5/5] END .......C=1, gamma=1, kernel=linear;, score=0.888 total time=   0.0s\n",
            "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.881 total time=   0.0s\n",
            "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.903 total time=   0.0s\n",
            "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.911 total time=   0.0s\n",
            "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.858 total time=   0.0s\n",
            "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.884 total time=   0.0s\n",
            "[CV 1/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.807 total time=   0.0s\n",
            "[CV 2/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.792 total time=   0.0s\n",
            "[CV 3/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.799 total time=   0.0s\n",
            "[CV 4/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.761 total time=   0.0s\n",
            "[CV 5/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.828 total time=   0.0s\n",
            "[CV 1/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.870 total time=   0.0s\n",
            "[CV 2/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.881 total time=   0.0s\n",
            "[CV 3/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.851 total time=   0.0s\n",
            "[CV 5/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.888 total time=   0.0s\n",
            "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.833 total time=   0.0s\n",
            "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.859 total time=   0.0s\n",
            "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.840 total time=   0.0s\n",
            "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.821 total time=   0.0s\n",
            "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.825 total time=   0.0s\n",
            "[CV 1/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.799 total time=   0.0s\n",
            "[CV 2/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.848 total time=   0.0s\n",
            "[CV 3/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.829 total time=   0.0s\n",
            "[CV 4/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.810 total time=   0.0s\n",
            "[CV 5/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.813 total time=   0.0s\n",
            "[CV 1/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.870 total time=   0.0s\n",
            "[CV 2/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.881 total time=   0.0s\n",
            "[CV 3/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.851 total time=   0.0s\n",
            "[CV 5/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.888 total time=   0.0s\n",
            "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.747 total time=   0.0s\n",
            "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.766 total time=   0.0s\n",
            "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.743 total time=   0.0s\n",
            "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.772 total time=   0.0s\n",
            "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.780 total time=   0.0s\n",
            "[CV 1/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.677 total time=   0.0s\n",
            "[CV 2/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.677 total time=   0.0s\n",
            "[CV 3/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.680 total time=   0.0s\n",
            "[CV 4/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.683 total time=   0.0s\n",
            "[CV 5/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.679 total time=   0.0s\n",
            "[CV 1/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.870 total time=   0.0s\n",
            "[CV 2/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.881 total time=   0.0s\n",
            "[CV 3/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.851 total time=   0.0s\n",
            "[CV 5/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.888 total time=   0.0s\n",
            "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.677 total time=   0.0s\n",
            "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.677 total time=   0.1s\n",
            "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.680 total time=   0.1s\n",
            "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.679 total time=   0.0s\n",
            "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.679 total time=   0.0s\n",
            "[CV 1/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.677 total time=   0.0s\n",
            "[CV 2/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.677 total time=   0.0s\n",
            "[CV 3/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.680 total time=   0.0s\n",
            "[CV 4/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.679 total time=   0.0s\n",
            "[CV 5/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.679 total time=   0.0s\n",
            "[CV 1/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.870 total time=   0.0s\n",
            "[CV 2/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.881 total time=   0.0s\n",
            "[CV 3/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.851 total time=   0.0s\n",
            "[CV 5/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.888 total time=   0.0s\n",
            "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.874 total time=   0.1s\n",
            "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.911 total time=   0.1s\n",
            "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.866 total time=   0.1s\n",
            "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.810 total time=   0.0s\n",
            "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.866 total time=   0.1s\n",
            "[CV 1/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.584 total time=   0.0s\n",
            "[CV 2/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.543 total time=   0.0s\n",
            "[CV 3/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.554 total time=   0.0s\n",
            "[CV 4/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.545 total time=   0.0s\n",
            "[CV 5/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.549 total time=   0.0s\n",
            "[CV 1/5] END ......C=10, gamma=1, kernel=linear;, score=0.877 total time=   0.0s\n",
            "[CV 2/5] END ......C=10, gamma=1, kernel=linear;, score=0.862 total time=   0.0s\n",
            "[CV 3/5] END ......C=10, gamma=1, kernel=linear;, score=0.840 total time=   0.0s\n",
            "[CV 4/5] END ......C=10, gamma=1, kernel=linear;, score=0.858 total time=   0.0s\n",
            "[CV 5/5] END ......C=10, gamma=1, kernel=linear;, score=0.881 total time=   0.0s\n",
            "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.896 total time=   0.0s\n",
            "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.929 total time=   0.0s\n",
            "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.911 total time=   0.0s\n",
            "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.873 total time=   0.0s\n",
            "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.903 total time=   0.0s\n",
            "[CV 1/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.766 total time=   0.0s\n",
            "[CV 2/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.758 total time=   0.0s\n",
            "[CV 3/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.781 total time=   0.0s\n",
            "[CV 4/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.761 total time=   0.0s\n",
            "[CV 5/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.784 total time=   0.0s\n",
            "[CV 1/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.877 total time=   0.0s\n",
            "[CV 2/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.862 total time=   0.0s\n",
            "[CV 3/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.840 total time=   0.0s\n",
            "[CV 4/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.858 total time=   0.1s\n",
            "[CV 5/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.881 total time=   0.0s\n",
            "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.874 total time=   0.0s\n",
            "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.892 total time=   0.0s\n",
            "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.874 total time=   0.0s\n",
            "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.851 total time=   0.0s\n",
            "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.884 total time=   0.0s\n",
            "[CV 1/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.877 total time=   0.0s\n",
            "[CV 2/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.877 total time=   0.0s\n",
            "[CV 3/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.836 total time=   0.0s\n",
            "[CV 5/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.869 total time=   0.0s\n",
            "[CV 1/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.877 total time=   0.0s\n",
            "[CV 2/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.862 total time=   0.0s\n",
            "[CV 3/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.840 total time=   0.0s\n",
            "[CV 4/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.858 total time=   0.1s\n",
            "[CV 5/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.881 total time=   0.0s\n",
            "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.822 total time=   0.0s\n",
            "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.859 total time=   0.0s\n",
            "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.844 total time=   0.0s\n",
            "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.821 total time=   0.0s\n",
            "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.825 total time=   0.0s\n",
            "[CV 1/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.803 total time=   0.0s\n",
            "[CV 2/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.848 total time=   0.0s\n",
            "[CV 3/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.829 total time=   0.0s\n",
            "[CV 4/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.810 total time=   0.0s\n",
            "[CV 5/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.813 total time=   0.0s\n",
            "[CV 1/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.877 total time=   0.0s\n",
            "[CV 2/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.862 total time=   0.0s\n",
            "[CV 3/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.840 total time=   0.0s\n",
            "[CV 4/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.858 total time=   0.0s\n",
            "[CV 5/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.881 total time=   0.0s\n",
            "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.747 total time=   0.0s\n",
            "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.766 total time=   0.0s\n",
            "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.758 total time=   0.0s\n",
            "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.772 total time=   0.0s\n",
            "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.780 total time=   0.0s\n",
            "[CV 1/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.677 total time=   0.0s\n",
            "[CV 2/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.677 total time=   0.0s\n",
            "[CV 3/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.680 total time=   0.0s\n",
            "[CV 4/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.683 total time=   0.0s\n",
            "[CV 5/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.679 total time=   0.0s\n",
            "[CV 1/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.877 total time=   0.0s\n",
            "[CV 2/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.862 total time=   0.0s\n",
            "[CV 3/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.840 total time=   0.0s\n",
            "[CV 4/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.858 total time=   0.0s\n",
            "[CV 5/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.881 total time=   0.0s\n",
            "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.874 total time=   0.1s\n",
            "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.911 total time=   0.1s\n",
            "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.810 total time=   0.1s\n",
            "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.866 total time=   0.1s\n",
            "[CV 1/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.584 total time=   0.0s\n",
            "[CV 2/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.546 total time=   0.0s\n",
            "[CV 3/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.550 total time=   0.0s\n",
            "[CV 4/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.537 total time=   0.0s\n",
            "[CV 5/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.541 total time=   0.0s\n",
            "[CV 1/5] END .....C=100, gamma=1, kernel=linear;, score=0.881 total time=   1.0s\n",
            "[CV 2/5] END .....C=100, gamma=1, kernel=linear;, score=0.870 total time=   0.5s\n",
            "[CV 3/5] END .....C=100, gamma=1, kernel=linear;, score=0.859 total time=   0.3s\n",
            "[CV 4/5] END .....C=100, gamma=1, kernel=linear;, score=0.858 total time=   0.7s\n",
            "[CV 5/5] END .....C=100, gamma=1, kernel=linear;, score=0.873 total time=   0.7s\n",
            "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.892 total time=   0.0s\n",
            "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.918 total time=   0.0s\n",
            "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.877 total time=   0.0s\n",
            "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.869 total time=   0.0s\n",
            "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.881 total time=   0.0s\n",
            "[CV 1/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.766 total time=   0.0s\n",
            "[CV 2/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.770 total time=   0.0s\n",
            "[CV 3/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.784 total time=   0.0s\n",
            "[CV 4/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.754 total time=   0.0s\n",
            "[CV 5/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.795 total time=   0.0s\n",
            "[CV 1/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.881 total time=   1.0s\n",
            "[CV 2/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.870 total time=   0.6s\n",
            "[CV 3/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.859 total time=   0.3s\n",
            "[CV 4/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.858 total time=   0.7s\n",
            "[CV 5/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.873 total time=   0.7s\n",
            "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.885 total time=   0.0s\n",
            "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.933 total time=   0.0s\n",
            "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.903 total time=   0.0s\n",
            "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.869 total time=   0.0s\n",
            "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.877 total time=   0.0s\n",
            "[CV 1/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.874 total time=   0.0s\n",
            "[CV 2/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.866 total time=   0.0s\n",
            "[CV 3/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.848 total time=   0.0s\n",
            "[CV 4/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.851 total time=   0.0s\n",
            "[CV 5/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.881 total time=   0.0s\n",
            "[CV 1/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.881 total time=   1.0s\n",
            "[CV 2/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.870 total time=   0.5s\n",
            "[CV 3/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.859 total time=   0.3s\n",
            "[CV 4/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.858 total time=   0.8s\n",
            "[CV 5/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.873 total time=   0.7s\n",
            "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.866 total time=   0.1s\n",
            "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.888 total time=   0.0s\n",
            "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.870 total time=   0.0s\n",
            "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.836 total time=   0.0s\n",
            "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.881 total time=   0.0s\n",
            "[CV 1/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.877 total time=   0.0s\n",
            "[CV 2/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.885 total time=   0.0s\n",
            "[CV 3/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.836 total time=   0.0s\n",
            "[CV 5/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.869 total time=   0.0s\n",
            "[CV 1/5] END .C=100, gamma=0.001, kernel=linear;, score=0.881 total time=   0.9s\n",
            "[CV 2/5] END .C=100, gamma=0.001, kernel=linear;, score=0.870 total time=   0.4s\n",
            "[CV 3/5] END .C=100, gamma=0.001, kernel=linear;, score=0.859 total time=   0.2s\n",
            "[CV 4/5] END .C=100, gamma=0.001, kernel=linear;, score=0.858 total time=   0.7s\n",
            "[CV 5/5] END .C=100, gamma=0.001, kernel=linear;, score=0.873 total time=   0.7s\n",
            "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.822 total time=   0.0s\n",
            "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.859 total time=   0.0s\n",
            "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.844 total time=   0.0s\n",
            "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.821 total time=   0.0s\n",
            "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.825 total time=   0.0s\n",
            "[CV 1/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.803 total time=   0.0s\n",
            "[CV 2/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.848 total time=   0.0s\n",
            "[CV 3/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.829 total time=   0.0s\n",
            "[CV 4/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.810 total time=   0.0s\n",
            "[CV 5/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.813 total time=   0.0s\n",
            "[CV 1/5] END C=100, gamma=0.0001, kernel=linear;, score=0.881 total time=   0.9s\n",
            "[CV 2/5] END C=100, gamma=0.0001, kernel=linear;, score=0.870 total time=   0.4s\n",
            "[CV 3/5] END C=100, gamma=0.0001, kernel=linear;, score=0.859 total time=   0.2s\n",
            "[CV 4/5] END C=100, gamma=0.0001, kernel=linear;, score=0.858 total time=   0.6s\n",
            "[CV 5/5] END C=100, gamma=0.0001, kernel=linear;, score=0.873 total time=   0.7s\n",
            "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.874 total time=   0.1s\n",
            "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.911 total time=   0.1s\n",
            "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.866 total time=   0.1s\n",
            "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.810 total time=   0.1s\n",
            "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.866 total time=   0.1s\n",
            "[CV 1/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.584 total time=   0.0s\n",
            "[CV 2/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.550 total time=   0.1s\n",
            "[CV 3/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.546 total time=   0.0s\n",
            "[CV 4/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.537 total time=   0.0s\n",
            "[CV 5/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.541 total time=   0.0s\n",
            "[CV 1/5] END ....C=1000, gamma=1, kernel=linear;, score=0.866 total time=   6.7s\n",
            "[CV 2/5] END ....C=1000, gamma=1, kernel=linear;, score=0.881 total time=  17.9s\n",
            "[CV 3/5] END ....C=1000, gamma=1, kernel=linear;, score=0.859 total time=   3.7s\n",
            "[CV 4/5] END ....C=1000, gamma=1, kernel=linear;, score=0.862 total time=  16.4s\n",
            "[CV 5/5] END ....C=1000, gamma=1, kernel=linear;, score=0.869 total time=   7.0s\n",
            "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.881 total time=   0.0s\n",
            "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.907 total time=   0.0s\n",
            "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.877 total time=   0.0s\n",
            "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.847 total time=   0.0s\n",
            "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.892 total time=   0.0s\n",
            "[CV 1/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.766 total time=   0.0s\n",
            "[CV 2/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.751 total time=   0.0s\n",
            "[CV 3/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.784 total time=   0.0s\n",
            "[CV 4/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.754 total time=   0.0s\n",
            "[CV 5/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.795 total time=   0.0s\n",
            "[CV 1/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.866 total time=   6.8s\n",
            "[CV 2/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.881 total time=  18.2s\n",
            "[CV 3/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.859 total time=   3.6s\n",
            "[CV 4/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.862 total time=  14.4s\n",
            "[CV 5/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.869 total time=   7.0s\n",
            "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.885 total time=   0.0s\n",
            "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.918 total time=   0.1s\n",
            "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.896 total time=   0.1s\n",
            "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.858 total time=   0.1s\n",
            "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.892 total time=   0.0s\n",
            "[CV 1/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.855 total time=   0.1s\n",
            "[CV 2/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.859 total time=   0.1s\n",
            "[CV 3/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.825 total time=   0.1s\n",
            "[CV 4/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.836 total time=   0.1s\n",
            "[CV 5/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.881 total time=   0.2s\n",
            "[CV 1/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.866 total time=   7.4s\n",
            "[CV 2/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.881 total time=  18.2s\n",
            "[CV 3/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.859 total time=   3.4s\n",
            "[CV 4/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.862 total time=  14.0s\n",
            "[CV 5/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.869 total time=   6.9s\n",
            "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.881 total time=   0.0s\n",
            "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.881 total time=   0.0s\n",
            "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.874 total time=   0.0s\n",
            "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.873 total time=   0.0s\n",
            "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.884 total time=   0.0s\n",
            "[CV 1/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.870 total time=   0.0s\n",
            "[CV 2/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.881 total time=   0.0s\n",
            "[CV 3/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.851 total time=   0.0s\n",
            "[CV 5/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.888 total time=   0.0s\n",
            "[CV 1/5] END C=1000, gamma=0.001, kernel=linear;, score=0.866 total time=   6.5s\n",
            "[CV 2/5] END C=1000, gamma=0.001, kernel=linear;, score=0.881 total time=  18.1s\n",
            "[CV 3/5] END C=1000, gamma=0.001, kernel=linear;, score=0.859 total time=   3.5s\n",
            "[CV 4/5] END C=1000, gamma=0.001, kernel=linear;, score=0.862 total time=  13.8s\n",
            "[CV 5/5] END C=1000, gamma=0.001, kernel=linear;, score=0.869 total time=   6.9s\n",
            "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.870 total time=   0.0s\n",
            "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.892 total time=   0.0s\n",
            "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.840 total time=   0.0s\n",
            "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.873 total time=   0.0s\n",
            "[CV 1/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.877 total time=   0.0s\n",
            "[CV 2/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.885 total time=   0.0s\n",
            "[CV 3/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.866 total time=   0.0s\n",
            "[CV 4/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.836 total time=   0.0s\n",
            "[CV 5/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.869 total time=   0.0s\n",
            "[CV 1/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.866 total time=   6.7s\n",
            "[CV 2/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.881 total time=  18.2s\n",
            "[CV 3/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.859 total time=   3.7s\n",
            "[CV 4/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.862 total time=  14.1s\n",
            "[CV 5/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.869 total time=   6.9s\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
              "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 1000],\n",
              "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001, 0.0001],\n",
              "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;, &#x27;sigmoid&#x27;, &#x27;linear&#x27;]},\n",
              "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n",
              "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 1000],\n",
              "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001, 0.0001],\n",
              "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;, &#x27;sigmoid&#x27;, &#x27;linear&#x27;]},\n",
              "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(estimator=SVC(),\n",
              "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
              "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
              "                         'kernel': ['rbf', 'sigmoid', 'linear']},\n",
              "             verbose=3)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# defining parameter range \n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
        "\t\t\t'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
        "\t\t\t'kernel': ['rbf','sigmoid', 'linear']} \n",
        "\n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) \n",
        "# fitting the model for grid search \n",
        "grid.fit(X_train.loc[:, sel.support_], y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "colab_type": "code",
        "id": "9EddeYut6990",
        "outputId": "9d93e442-0846-45eb-eeba-affcafc986dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.93      0.93      0.93       247\n",
            "      malign       0.80      0.80      0.80        89\n",
            "\n",
            "    accuracy                           0.89       336\n",
            "   macro avg       0.86      0.86      0.86       336\n",
            "weighted avg       0.89      0.89      0.89       336\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(grid.best_params_) \n",
        "grid_predictions = grid.predict(X_test.loc[:,sel.support_]) \n",
        "\n",
        "# print classification report \n",
        "print(classification_report(y_test, grid_predictions)) \n",
        "pickle.dump(grid, open('../svc_ga.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "colab_type": "code",
        "id": "XNundqaaAloc",
        "outputId": "19b0dc68-686a-4e9c-9804-4bae1144c93e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Requested API level 29 is larger than maximum we have, returning API level 28 instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['android.permission.READ_EXTERNAL_STORAGE', 'com.sonymobile.home.permission.PROVIDER_INSERT_BADGE', 'android.permission.AUTHENTICATE_ACCOUNTS', 'android.permission.READ_PROFILE', 'android.permission.READ_PHONE_STATE', 'android.permission.READ_CONTACTS', 'android.permission.ACCESS_WIFI_STATE', 'android.permission.INSTALL_SHORTCUT', 'android.permission.REQUEST_INSTALL_PACKAGES', 'android.permission.WRITE_CONTACTS', 'android.permission.MANAGE_ACCOUNTS', 'android.permission.ACCESS_NETWORK_STATE', 'com.whatsapp.permission.MAPS_RECEIVE', 'com.sec.android.provider.badge.permission.WRITE', 'com.whatsapp.permission.BROADCAST', 'android.permission.RECORD_AUDIO', 'android.permission.NFC', 'android.permission.USE_FULL_SCREEN_INTENT', 'com.whatsapp.permission.REGISTRATION', 'android.permission.WAKE_LOCK', 'com.android.launcher.permission.INSTALL_SHORTCUT', 'android.permission.FOREGROUND_SERVICE', 'android.permission.VIBRATE', 'com.google.android.providers.gsf.permission.READ_GSERVICES', 'android.permission.USE_BIOMETRIC', 'android.permission.GET_ACCOUNTS', 'android.permission.USE_CREDENTIALS', 'com.sec.android.provider.badge.permission.READ', 'com.huawei.android.launcher.permission.WRITE_SETTINGS', 'android.permission.ACCESS_FINE_LOCATION', 'android.permission.GET_TASKS', 'android.permission.READ_SYNC_SETTINGS', 'android.permission.WRITE_SYNC_SETTINGS', 'android.permission.READ_SYNC_STATS', 'com.huawei.android.launcher.permission.READ_SETTINGS', 'com.huawei.android.launcher.permission.CHANGE_BADGE', 'com.google.android.c2dm.permission.RECEIVE', 'android.permission.RECEIVE_SMS', 'android.permission.BLUETOOTH', 'android.permission.MODIFY_AUDIO_SETTINGS', 'android.permission.WRITE_EXTERNAL_STORAGE', 'com.sonyericsson.home.permission.BROADCAST_BADGE', 'android.permission.ACCESS_COARSE_LOCATION', 'com.whatsapp.sticker.READ', 'android.permission.CAMERA', 'android.permission.BROADCAST_STICKY', 'android.permission.CHANGE_NETWORK_STATE', 'android.permission.SEND_SMS', 'com.android.launcher.permission.UNINSTALL_SHORTCUT', 'com.htc.launcher.permission.UPDATE_SHORTCUT', 'android.permission.INTERNET', 'android.permission.USE_FINGERPRINT', 'android.permission.CHANGE_WIFI_STATE', 'android.permission.RECEIVE_BOOT_COMPLETED', 'android.permission.MANAGE_OWN_CALLS', 'com.htc.launcher.permission.READ_SETTINGS']\n",
            "['benign']\n"
          ]
        }
      ],
      "source": [
        "def predict(apk):\n",
        "  vector = {}\n",
        "  a = APK(apk)\n",
        "  perm = a.get_permissions()\n",
        "  print(perm)\n",
        "  for d in features:\n",
        "    if d in perm:\n",
        "      vector[d]=1\n",
        "    else:\n",
        "      vector[d]=0\n",
        "  data = [ v for v in vector.values() ]\n",
        "  data = np.array(data)\n",
        "  print(grid.predict([data[sel.support_]]))\n",
        "\n",
        "#predict('/content/Ransomware/PornDroid/1c53e2c34d1219a2fae8fcf8ec872ac8.apk')\n",
        "predict('../dataset/benign/com.whatsapp.apk')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "genetic_algorithm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
